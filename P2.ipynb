{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---\n",
    "## First, I'll compute the camera calibration using chessboard images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib qt\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((6*9,3), np.float32)#(54, 3)\n",
    "#print(np.mgrid[0:9,0:6].T.reshape(-1,2))\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('../camera_cal/calibration*.jpg')\n",
    "img=cv2.imread(images[0])\n",
    "'''plt.subplot(1,2,1)\n",
    "plt.imshow(img)\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(img_undist)'''\n",
    "# Step through the list and search for chessboard corners\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6),None)\n",
    "\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "        #cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "        \n",
    "       \n",
    "        # Draw and display the corners\n",
    "        #plt.subplot(4,5,fname.index(fname)+1)\n",
    "        \n",
    "        #cv2.imshow('img',img)\n",
    "        #cv2.waitKey(600)\n",
    "ret,mtx,dist,rvecs,tvecs=cv2.calibrateCamera(objpoints,imgpoints,img.shape[1::-1],None,None)\n",
    "#cv2.destroyAllWindows()\n",
    "def undistortion(img):\n",
    "    return cv2.undistort(img,mtx,dist,None,mtx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And so on and so forth..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "def thr_rgb(image,rthr=(0,255),gthr=(0,255),bthr=(0,255)):#此函数用于决定RGB中哪个通道最适合以及合适的阈值\n",
    "    #gray=cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    R=image[:,:,0]\n",
    "    G=image[:,:,1]\n",
    "    B=image[:,:,2]\n",
    "    binaryr = np.zeros_like(R)\n",
    "    binaryr[(R > rthr[0]) & (R <= rthr[1])] = 1\n",
    "    binaryg = np.zeros_like(R)\n",
    "    binaryg[(G > gthr[0]) & (G <= gthr[1])] = 1\n",
    "    binaryb = np.zeros_like(R)\n",
    "    binaryb[(B > bthr[0]) & (B <= bthr[1])] = 1\n",
    "    if(rthr[0]!=0 & rthr[1]!=255 ):\n",
    "        print(1)\n",
    "        return binaryr\n",
    "    elif(gthr[0]!=0 &gthr[1]!=255):\n",
    "        \n",
    "        return binaryg\n",
    "    else:\n",
    "        return binaryb\n",
    "\n",
    "#plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thr_hls(image,hthr=(0,179),lthr=(0,255),sthr=(0,255)):\n",
    "    hls = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "    H=hls[:,:,0]\n",
    "    L=hls[:,:,1]\n",
    "    S=hls[:,:,2]\n",
    "    binaryh = np.zeros_like(H)\n",
    "    binaryh[(H > hthr[0]) & (H <= hthr[1])] = 1\n",
    "    binaryl = np.zeros_like(H)\n",
    "    binaryl[(L > lthr[0]) & (L <= lthr[1])] = 1\n",
    "    binarys = np.zeros_like(H)\n",
    "    binarys[(S > sthr[0]) & (S <= sthr[1])] = 1\n",
    "    if(hthr[0]!=0 & hthr[1]!=179):\n",
    "        return binaryh\n",
    "    elif(lthr[0]!=0 & lthr[1]!=255):\n",
    "        return binaryl\n",
    "    else:\n",
    "        return binarys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thr_sobel(image,sobelx_thr=(0,255)):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0)\n",
    "    abs_sobelx = np.absolute(sobelx)\n",
    "    scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "    #plt.imshow(scaled_sobel,cmap='gray')\n",
    "    sxbinary = np.zeros_like(scaled_sobel)\n",
    "    sxbinary[(scaled_sobel >= sobelx_thr[0]) & (scaled_sobel <= sobelx_thr[1])] = 1\n",
    "    return sxbinary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os#此格用于查看8副图片各种threshold的效果\n",
    "dic=os.listdir(\"../test_images/\")\n",
    "#plt.figure(figsize=(80,80),dpi=180)\n",
    "\n",
    "#image=mpimg.imread(\"../test_images/\"+dic[7])\n",
    "#image=thr_sobel(image,sobelx_thr=(40,130))\n",
    "#plt.imshow(image,cmap='gray')\n",
    "for i in range(len(dic)):\n",
    "    image=mpimg.imread(\"../test_images/\"+dic[i])\n",
    "    undistort=undistortion(image)\n",
    "    image1=thr_rgb(undistort,rthr=(0,255),gthr=(180,255),bthr=(0,255))\n",
    "    \n",
    "    image2=thr_hls(undistort,hthr=(0,255),lthr=(0,255),sthr=(120,255))#120\n",
    "    image3=thr_sobel(undistort,sobelx_thr=(30,130))#最小值大于40很多边缘检测不到\n",
    "    #combine=image1&image2|image3\n",
    "    color_img=255*np.dstack((image1,image2,image3))\n",
    "    #warped=persp_trans(combine,src,dst)\n",
    "    \n",
    "    #pixelbelongtolane=lane_pixels(warped)\n",
    "    #image_3d=fit_poly_3d(warped)\n",
    "    result=detect(image)\n",
    "    plt.subplot(2,4,i+1)\n",
    "    #plt.imshow(warped,cmap='gray')\n",
    "    #plt.plot(his_image)\n",
    "    plt.imshow(color_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2=mpimg.imread(\"../test_images/\"+dic[1])\n",
    "src=np.float32([[605,442],[675,442],[275,674],[1042,674]])\n",
    "dst=np.float32([[300,0],[1000,0],[300,719],[1000,719]])\n",
    "\n",
    "'''cv2.circle(img2,(605,442),10,(0,255,0),20)\n",
    "cv2.circle(img2,(675,442),10,(0,255,0),20)\n",
    "cv2.circle(img2,(1042,674),10,(0,255,0),20)\n",
    "cv2.circle(img2,(275,674),10,(0,255,0),20)'''\n",
    "#plt.imshow(img2)\n",
    "def persp_trans(img,src,dst):\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    warped = cv2.warpPerspective(img, M, (1280,720))\n",
    "    return warped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist(image):\n",
    "    half_image=image[image.shape[0]//2:,:]\n",
    "    histgram_image=np.sum(half_image,axis=0)\n",
    "    return histgram_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lane_pixels(image):#利用sliding window寻找车道线\n",
    "    his=hist(image)\n",
    "    image_3d=np.dstack((image,image,image))\n",
    "    mid=image.shape[1]//2\n",
    "    lxbase=np.argmax(his[200:mid])+200\n",
    "    rxbase=np.argmax(his[mid:-200])+mid\n",
    "    numofwindow=10\n",
    "    winheight=np.int(image.shape[0]//numofwindow)\n",
    "    margin=100\n",
    "    minpix=50\n",
    "    nonzero = image.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    lx_current = lxbase\n",
    "    rx_current = rxbase\n",
    "    left_index=[]\n",
    "    right_index=[]\n",
    "    for i in range(numofwindow):\n",
    "        win_y_low = image.shape[0] - (i+1)*winheight\n",
    "        win_y_high = image.shape[0] - i*winheight\n",
    "        win_xleft_low = lx_current - margin\n",
    "        win_xleft_high = lx_current + margin\n",
    "        win_xright_low = rx_current - margin\n",
    "        win_xright_high = rx_current + margin\n",
    "        \n",
    "        cv2.rectangle(image_3d,(win_xleft_low,win_y_low),\n",
    "        (win_xleft_high,win_y_high),(0,255,0), 4) \n",
    "        cv2.rectangle(image_3d,(win_xright_low,win_y_low),\n",
    "        (win_xright_high,win_y_high),(0,255,0), 4) \n",
    "        \n",
    "        inwin_left_index = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        inwin_right_index = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        \n",
    "        left_index.append(inwin_left_index)\n",
    "        right_index.append(inwin_right_index)\n",
    "        \n",
    "        if len(inwin_left_index) > minpix:\n",
    "            lx_current = np.int(np.mean(nonzerox[inwin_left_index]))\n",
    "        if len(inwin_right_index) > minpix:        \n",
    "            rx_current = np.int(np.mean(nonzerox[inwin_right_index]))\n",
    "        \n",
    "    left_index = np.concatenate(left_index)\n",
    "    right_index = np.concatenate(right_index)\n",
    "    leftx = nonzerox[left_index]\n",
    "    lefty = nonzeroy[left_index] \n",
    "    rightx = nonzerox[right_index]\n",
    "    righty = nonzeroy[right_index]\n",
    "        \n",
    "    return leftx, lefty, rightx, righty, image_3d\n",
    "    #return image_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_poly_3d(image):#拟合并画车道线\n",
    "    leftx, lefty, rightx, righty, image_3d = lane_pixels(image)\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    ploty = np.linspace(0, image.shape[0]-1, image.shape[0] )\n",
    "  \n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    \n",
    "    image_3d[lefty, leftx] = [255, 0, 0]\n",
    "    image_3d[righty, rightx] = [0, 0, 255]\n",
    "    \n",
    "    #plt.plot(left_fitx, ploty, color='yellow')\n",
    "    #plt.plot(right_fitx, ploty, color='yellow')\n",
    "   \n",
    "    return image_3d,left_fit,right_fit,left_fitx,right_fitx,ploty\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_curvature(undist,left_fitx,right_fitx,ploty):\n",
    "    ym_per_pix = 30/720 \n",
    "    xm_per_pix = 3.7/700\n",
    "    left_fit_cr = np.polyfit(ploty*ym_per_pix, left_fitx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(ploty*ym_per_pix, right_fitx*xm_per_pix, 2)\n",
    "    y_eval = np.max(ploty*ym_per_pix)\n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "    car_center = undist.shape[1] / 2\n",
    "    i = undist.shape[0]-1\n",
    "    vehicle_position = (car_center - (right_fitx[i] + left_fitx[i])/2 )* xm_per_pix \n",
    "    vehicle_position=float('%.2f' % vehicle_position)\n",
    "    return left_curverad,right_curverad,vehicle_position\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_on_original(undist ,warped ,dst ,src ,left_fitx ,right_fitx ,ploty ,left_curverad ,right_curverad ,vehicle_position):\n",
    "    warp_zero = np.zeros_like(warped).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "    M = cv2.getPerspectiveTransform(dst, src)\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "    if (vehicle_position > 0.3) | (vehicle_position < -0.3)  :\n",
    "        cv2.fillPoly(color_warp, np.int_([pts]), (255,0, 0))\n",
    "    else :\n",
    "        cv2.fillPoly(color_warp, np.int_([pts]), (0,255,0))\n",
    "    \n",
    "    cv2.polylines(color_warp, np.int32([pts_left]), isClosed=False, color=(255,255,0), thickness=20)\n",
    "    cv2.polylines(color_warp, np.int32([pts_right]), isClosed=False, color=(255,255,255), thickness=20)  \n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, M, (img.shape[1], img.shape[0])) \n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(undist, 1, newwarp, 0.3, 0)\n",
    "    ### writting the curvature of the lane and vehicle position with respect to center   \n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    average=str(int((left_curverad+right_curverad)/2))\n",
    "     \n",
    "    result = cv2.putText(result, 'Radius of Curvature:  ' + average+'m'  , (30, 30), font, 0.8, (0, 255, 0), 2, cv2.LINE_AA) \n",
    "    if vehicle_position<=0:\n",
    "        result = cv2.putText(result, 'Vehicle is '+str(-vehicle_position)+'m left of center' , (30, 60), font, 0.8, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "    else:\n",
    "        result = cv2.putText(result, 'Vehicle is '+str(vehicle_position)+'m right of center' , (30, 60), font, 0.8, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "        \n",
    "\n",
    "    return result\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_poly_last(img_shape, leftx, lefty, rightx, righty):##依据上一帧来拟合这一帧\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    ploty = np.linspace(0, img_shape[0]-1, img_shape[0])\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    return left_fitx, right_fitx, ploty\n",
    "    #return image_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def near_search(image,left_fit,right_fit,ploty):#依据上一帧来检测这一帧\n",
    "    margin=100\n",
    "    nonzero = image.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    inwin_left_index = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + \n",
    "                    left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + \n",
    "                    left_fit[1]*nonzeroy + left_fit[2] + margin)))\n",
    "    inwin_right_index = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + \n",
    "                    right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + \n",
    "                    right_fit[1]*nonzeroy + right_fit[2] + margin)))\n",
    "    leftx = nonzerox[inwin_left_index]\n",
    "    lefty = nonzeroy[inwin_left_index] \n",
    "    rightx = nonzerox[inwin_right_index]\n",
    "    righty = nonzeroy[inwin_right_index]\n",
    "    left_fitx, right_fitx, ploty = fit_poly_last(image.shape, leftx, lefty, rightx, righty)\n",
    "    out_img = np.dstack((image, image, image))*255\n",
    "    window_img = np.zeros_like(out_img)\n",
    "    out_img[lefty, leftx] = [255, 0, 0]\n",
    "    out_img[righty, rightx] = [0, 0, 255]\n",
    "    \n",
    "    left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "    left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin,ploty])))])\n",
    "    left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "    right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "    right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin,ploty])))])\n",
    "    right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "    cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "    cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255, 0))\n",
    "    result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "    \n",
    "    plt.plot(left_fitx, ploty, color='yellow')\n",
    "    plt.plot(right_fitx, ploty, color='yellow')\n",
    "    return result,left_fitx,right_fitx,ploty\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x10879940>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#try it on single image,\n",
    "'''timage = mpimg.imread(\"../test_images/\"+dic[7])\n",
    "tundistort=undistortion(timage)\n",
    "timage1=thr_rgb(tundistort,rthr=(0,255),gthr=(180,255),bthr=(0,255))\n",
    "   \n",
    "timage2=thr_hls(tundistort,hthr=(0,255),lthr=(0,255),sthr=(120,255))\n",
    "timage3=thr_sobel(tundistort,sobelx_thr=(38,130))#30最小值大于40很多边缘检测不到\n",
    "tcombine=timage1&timage2|timage3   \n",
    "twarped=persp_trans(tcombine,src,dst)\n",
    "fit=fit_poly_3d(twarped)\n",
    "curve=get_curvature(tundistort,fit[3] ,fit[4] ,fit[5])\n",
    "result=print_on_original(tundistort ,twarped ,dst ,src ,fit[3] ,fit[4] ,fit[5] ,curve[0] ,curve[1] ,curve[2])\n",
    "\n",
    "fitpoly=fit[0]\n",
    "\n",
    "second_img=mpimg.imread(\"../test_images/\"+dic[2])\n",
    "stundistort=undistortion(second_img)\n",
    "stimage1=thr_rgb(stundistort,rthr=(0,255),gthr=(180,255),bthr=(0,255))\n",
    "stimage2=thr_hls(stundistort,hthr=(0,255),lthr=(0,255),sthr=(120,255))\n",
    "stimage3=thr_sobel(stundistort,sobelx_thr=(30,130))#最小值大于40很多边缘检测不到\n",
    "stcombine=stimage1&stimage2|stimage3\n",
    "stwarped=persp_trans(stcombine)\n",
    "\n",
    "search_near=near_search(stwarped,fit[1],fit[2],fit[3])\n",
    "plt.imshow(fit[0])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(image):\n",
    "    undistort=undistortion(image)\n",
    "    image1=thr_rgb(undistort,rthr=(0,255),gthr=(180,255),bthr=(0,255))\n",
    "    image2=thr_hls(undistort,hthr=(0,255),lthr=(0,255),sthr=(120,255))#120\n",
    "    image3=thr_sobel(undistort,sobelx_thr=(30,130))#最小值大于40很多边缘检测不到\n",
    "    combine=image1&image2|image3\n",
    "    warped=persp_trans(combine,src,dst)\n",
    "    fit=fit_poly_3d(warped)\n",
    "    curve=get_curvature(undistort,fit[3] ,fit[4] ,fit[5])\n",
    "    result=print_on_original(undistort ,warped ,dst ,src ,fit[3] ,fit[4] ,fit[5] ,curve[0] ,curve[1] ,curve[2])\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: moviepy in e:\\anaconda\\install\\lib\\site-packages (0.2.3.5)\n",
      "Requirement already satisfied: numpy in e:\\anaconda\\install\\lib\\site-packages (from moviepy) (1.15.4)\n",
      "Requirement already satisfied: decorator<5.0,>=4.0.2 in e:\\anaconda\\install\\lib\\site-packages (from moviepy) (4.3.0)\n",
      "Requirement already satisfied: imageio<3.0,>=2.1.2 in e:\\anaconda\\install\\lib\\site-packages (from moviepy) (2.4.1)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.11.2 in e:\\anaconda\\install\\lib\\site-packages (from moviepy) (4.28.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install moviepy\n",
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video project_video_output.mp4\n",
      "[MoviePy] Writing video project_video_output.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████▉| 1260/1261 [04:21<00:00,  5.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: project_video_output.mp4 \n",
      "\n",
      "Wall time: 4min 23s\n"
     ]
    }
   ],
   "source": [
    "white_output = 'project_video_output.mp4'\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "white_clip = clip1.fl_image(detect) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
